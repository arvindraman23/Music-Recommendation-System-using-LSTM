{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f809c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Concatenate, Dropout, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ed2b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27540/27540 [==============================] - 106s 4ms/step - loss: 0.1203 - accuracy: 0.8650 - val_loss: 0.0681 - val_accuracy: 0.9598\n",
      "Epoch 2/10\n",
      "27540/27540 [==============================] - 98s 4ms/step - loss: 0.1079 - accuracy: 0.8788 - val_loss: 0.0691 - val_accuracy: 0.9560\n",
      "Epoch 3/10\n",
      "27540/27540 [==============================] - 98s 4ms/step - loss: 0.1075 - accuracy: 0.8791 - val_loss: 0.0686 - val_accuracy: 0.9549\n",
      "Epoch 4/10\n",
      "27540/27540 [==============================] - 93s 3ms/step - loss: 0.1073 - accuracy: 0.8790 - val_loss: 0.0667 - val_accuracy: 0.9569\n",
      "Epoch 5/10\n",
      "27540/27540 [==============================] - 92s 3ms/step - loss: 0.1075 - accuracy: 0.8791 - val_loss: 0.0676 - val_accuracy: 0.9571\n",
      "Epoch 6/10\n",
      "27540/27540 [==============================] - 99s 4ms/step - loss: 0.1073 - accuracy: 0.8790 - val_loss: 0.0671 - val_accuracy: 0.9572\n",
      "Epoch 7/10\n",
      "27540/27540 [==============================] - 100s 4ms/step - loss: 0.1073 - accuracy: 0.8791 - val_loss: 0.0703 - val_accuracy: 0.9515\n",
      "Epoch 8/10\n",
      "27540/27540 [==============================] - 94s 3ms/step - loss: 0.1072 - accuracy: 0.8790 - val_loss: 0.0708 - val_accuracy: 0.9510\n",
      "Epoch 9/10\n",
      "27540/27540 [==============================] - 92s 3ms/step - loss: 0.1073 - accuracy: 0.8785 - val_loss: 0.0687 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "27540/27540 [==============================] - 95s 3ms/step - loss: 0.1073 - accuracy: 0.8788 - val_loss: 0.0689 - val_accuracy: 0.9535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24b0f5f3eb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the spotify dataset into pandas dataframe\n",
    "# Rows with error are skipped and we choose the dataset in a random order\n",
    "spotifyDataset = pd.read_csv('spotify_data_1m.csv', on_bad_lines='skip', skiprows=lambda i: i > 0 and random.random() > 0.95)\n",
    "\n",
    "# Function to preprocess the textual data from the dataset\n",
    "def preprocessTextData():\n",
    "    # Genre data tokenized and padded according to max length\n",
    "    textTokenizer = Tokenizer(num_words=5000)\n",
    "    textTokenizer.fit_on_texts(spotifyDataset['genre'])\n",
    "    genreSequences = textTokenizer.texts_to_sequences(spotifyDataset['genre'])\n",
    "    maxSequenceLength = max(len(seq) for seq in genreSequences)\n",
    "    paddedGenreSequences = pad_sequences(genreSequences, maxlen=maxSequenceLength, padding='post')\n",
    "    \n",
    "    return paddedGenreSequences, maxSequenceLength, textTokenizer\n",
    "\n",
    "# Function to preprocess the numerical data from the dataset\n",
    "def preprocessNumericData():\n",
    "    # Numerical data scaled\n",
    "    numericData = spotifyDataset.select_dtypes(include=np.number)\n",
    "    standardScaler = StandardScaler()\n",
    "    scaledNumericData = standardScaler.fit_transform(numericData)\n",
    "    \n",
    "    return scaledNumericData, standardScaler\n",
    "\n",
    "paddedGenreSequences, maxSequenceLength, textTokenizer = preprocessTextData()\n",
    "scaledNumericData, standardScaler = preprocessNumericData()\n",
    "\n",
    "# Converting text and numeric sequences into np arrays\n",
    "X_text = np.array(paddedGenreSequences)\n",
    "X_numeric = np.array(scaledNumericData)\n",
    "\n",
    "# Function to define the LSTM model with layers for both text and numerical data\n",
    "def createModel():\n",
    "    # Textual Layer\n",
    "    textInputSequence = Input(shape=(maxSequenceLength,))\n",
    "    embeddingLayer = Embedding(input_dim=5000, output_dim=16, input_length=maxSequenceLength)(textInputSequence)\n",
    "    lstmLayer = LSTM(8, return_sequences=True, dropout=0.82, recurrent_dropout=0.82)(embeddingLayer)\n",
    "    textOutputSequence = Flatten()(Dropout(0.82)(lstmLayer))\n",
    "\n",
    "    # Numeric Layer\n",
    "    numericInputSequence = Input(shape=(X_numeric.shape[1],))\n",
    "    numericLayer = Dense(8, kernel_regularizer=l2(0.001))(numericInputSequence)\n",
    "    numericOutputSequence = Dropout(0.82)(numericLayer)\n",
    "    \n",
    "    return textInputSequence, numericInputSequence, textOutputSequence, numericOutputSequence\n",
    "\n",
    "textInputSequence, numericInputSequence, textOutputSequence, numericOutputSequence = createModel()\n",
    "\n",
    "combinedOutputSequence = Concatenate()([textOutputSequence, numericOutputSequence])\n",
    "combinedInputSequence = Dense(1, activation='tanh')(combinedInputSequence)\n",
    "\n",
    "# Initiating the model\n",
    "model = Model(inputs=[textInputSequence, numericInputSequence], outputs=combinedOutputSequence)\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy']) #use 'adamax' optimizer for 0.957\n",
    "\n",
    "# Splitting the dataset into training and validation set\n",
    "y = (spotifyDataset['popularity'] > spotifyDataset['popularity'].median()).astype(int)\n",
    "    \n",
    "X_train_text, X_test_text, X_train_numeric, X_test_numeric, y_train, y_test = train_test_split(\n",
    "    X_text, X_numeric, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "model.fit([X_train_text, X_train_numeric], y_train, epochs=10, batch_size=32, \n",
    "          validation_data=([X_test_text, X_test_numeric], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c5415e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6885/6885 [==============================] - 7s 1ms/step - loss: 0.0689 - accuracy: 0.9535\n",
      "6885/6885 [==============================] - 7s 1ms/step\n",
      "Accuracy: 95.351738%\n",
      "Precision: 92.944362%\n",
      "Recall: 98.007829%\n",
      "F1-Score: 95.408962%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "eval_result = model.evaluate([X_test_text, X_test_numeric], y_test)\n",
    "accuracy = eval_result[1]\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict([X_test_text, X_test_numeric])\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculating metrics\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "\n",
    "print(\"Accuracy: {:.6f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.6f}%\".format(precision * 100))\n",
    "print(\"Recall: {:.6f}%\".format(recall * 100))\n",
    "print(\"F1-Score: {:.6f}%\".format(f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5303736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34425/34425 [==============================] - 33s 964us/step\n",
      "Input Track Name: Lost in Translation /1\n",
      "Input Artist Name: infinite bisous\n",
      "-------------------------------------------------\n",
      "Top 3 Recommended Tracks:\n",
      "\n",
      "1) Hit the Road Jack (Pé Na Éstrada) by Mo' Horizons (Genre: trip-hop)\n",
      "2) Castigando by Max e Luan (Genre: forro)\n",
      "3) Casal Raiz - Ao Vivo by Xand Avião (Genre: forro)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def recommendTopSongs(input_track_name, input_artist, input_energy, input_loudness, input_acousticness, input_tempo, input_duration_ms, model, textTokenizer, standardScaler):\n",
    "    # Preprocessing input data for both text and numerical data\n",
    "    genreInputSequence = textTokenizer.texts_to_sequences([input_artist])\n",
    "    genreInputPaddedSequence = pad_sequences(genreInputSequence, maxlen=maxSequenceLength, padding='post')\n",
    "\n",
    "    numericInputData = np.array([[input_energy, input_loudness, input_acousticness, input_tempo, input_duration_ms, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "    scaledNumericInputData = standardScaler.transform(numericInputData)\n",
    "\n",
    "    # Predicting the popularity of the input song\n",
    "    inputPrediction = model.predict([genreInputPaddedSequence, np.array(scaledNumericInputData)])\n",
    "\n",
    "    # Extracting the genre and numeric data from all songs for recommendation\n",
    "    artistGenreList = spotifyDataset['artist_name']\n",
    "    trackNumericData = standardScaler.transform(spotifyDataset.select_dtypes(include=np.number))\n",
    "\n",
    "    artistGenreSequence = textTokenizer.texts_to_sequences(artistGenreList)\n",
    "    artistGenrePaddedSequence = pad_sequences(artistGenreSequence, maxlen=maxSequenceLength, padding='post')\n",
    "\n",
    "    # Predicting popularity for all songs\n",
    "    popularityPredictionList = model.predict([artistGenrePaddedSequence, np.array(trackNumericData)])\n",
    "\n",
    "    # Calculating cosine similarity between the input song and all other songs\n",
    "    cosineSimilarity = cosine_similarity(inputPrediction, popularityPredictionList).flatten()\n",
    "\n",
    "    # Fetching top 3 songs\n",
    "    recommendationCount = min(3, len(spotifyDataset) - 1)\n",
    "    selectedIndices = np.argsort(cosineSimilarity)[-recommendationCount:][::-1]\n",
    "    finalRecommendations = spotifyDataset[['track_name', 'artist_name', 'genre']].iloc[selectedIndices]\n",
    "\n",
    "    return finalRecommendations\n",
    "\n",
    "# Giving input song and its corresponding values (Using a random song from the dataset)\n",
    "song = spotifyDataset.sample(n=1)\n",
    "input_track_name = song['track_name'].values[0]\n",
    "input_artist = song['artist_name'].values[0]\n",
    "input_energy = song['energy'].values[0]\n",
    "input_loudness = song['loudness'].values[0]\n",
    "input_acousticness = song['acousticness'].values[0]\n",
    "input_tempo = song['tempo'].values[0]\n",
    "input_duration_ms = song['duration_ms'].values[0]\n",
    "\n",
    "top3Songs = recommendTopSongs(input_track_name, input_artist, input_energy, input_loudness, input_acousticness, input_tempo, input_duration_ms, model, textTokenizer, standardScaler)\n",
    "\n",
    "print(f\"Input Track Name: {input_track_name}\")\n",
    "print(f\"Input Artist Name: {input_artist}\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"Top 3 Recommended Tracks:\\n\")\n",
    "i=0\n",
    "for _, (song, artist, genre) in top3Songs.iterrows():\n",
    "    i=i+1\n",
    "    print(f\"{i}) {song} by {artist} (Genre: {genre})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
